<!DOCTYPE html>
<html lang="en">
  <head>
      <meta charset="UTF-8">
      <link rel="stylesheet" href="main.css">
      <link rel="icon" type="image/x-icon" href="assets/digit.png">
      <title>Opt2Skill</title>
  </head>
  <body>

    <div id="video_grid">
      <div class="video_wrapper">
        <div class="video_container">
          <video autoplay muted playsinline loop>
            <source src="assets/hardware/walking_indoor.mp4" type="video/mp4">
          </video>
        </div>
      </div>
      <div class="video_wrapper">
        <div class="video_container">
          <video autoplay muted playsinline loop>
            <source src="assets/hardware/walking_indoor_corridor.mp4" type="video/mp4">
          </video>
        </div>
      </div>
      <div class="video_wrapper">
        <div class="video_container">
          <video autoplay muted playsinline loop>
            <source src="assets/hardware/walking_backward.mp4" type="video/mp4">
          </video>
        </div>
      </div>
      <div class="video_wrapper">
        <div class="video_container">
          <video autoplay muted playsinline loop>
            <source src="assets/hardware/walking_indoor_dist.mp4" type="video/mp4">
          </video>
        </div>
      </div>
      <div class="video_wrapper">
        <div class="video_container">
          <video autoplay muted playsinline loop>
            <source src="assets/hardware/walking_push.mp4" type="video/mp4">
          </video>
        </div>
      </div>
      <div class="video_wrapper">
        <div class="video_container">
          <video autoplay muted playsinline loop>
            <source src="assets/hardware/walking_outdoor.mp4" type="video/mp4">
          </video>
        </div>
      </div>
      <div class="video_wrapper">
        <div class="video_container">
          <video autoplay muted playsinline loop>
            <source src="assets/hardware/box_pickup.mp4" type="video/mp4">
          </video>
        </div>
      </div>
      <div class="video_wrapper">
        <div class="video_container">
          <video autoplay muted playsinline loop>
            <source src="assets/hardware/stairs.mp4" type="video/mp4">
          </video>
        </div>
      </div>
      <div class="video_wrapper">
        <div class="video_container">
          <video autoplay muted playsinline loop>
            <source src="assets/hardware/walking_outdoor_grass.mp4" type="video/mp4">
          </video>
        </div>
      </div>
      <div class="video_wrapper">
        <div class="video_container">
          <video autoplay muted playsinline loop>
            <source src="assets/hardware/desk_manipulation.mp4" type="video/mp4">
          </video>
        </div>
      </div>
      <div class="video_wrapper">
        <div class="video_container">
          <video autoplay muted playsinline loop>
            <source src="assets/hardware/slides.mp4" type="video/mp4">
          </video>
        </div>
      </div>
      <div class="video_wrapper">
        <div class="video_container">
          <video autoplay muted playsinline loop>
            <source src="assets/hardware/walking_pick.mp4" type="video/mp4">
          </video>
        </div>
      </div>
    </div>


    <div id="title_slide">
        <div class="title_left">
            <h1>Opt2Skill: Imitating Dynamically-feasible Whole-Body <br> Trajectories for Versatile Humanoid Loco-Manipulation</h1>
        

            <div class="box alt">
              <div class="row uniform">
                <div class="2u"><a href="https://fukangl.github.io/">                   <span class="image fit"><img src="assets/author_photo/fukang.jpg" alt="Fukang Liu" /></span>Fukang Liu</a></div>
                <div class="2u"><a href="https://guzhaoyuan.com/">                      <span class="image fit"><img src="assets/author_photo/zhaoyuan.jpg" alt="Zhaoyuan Gu" /></span>Zhaoyuan Gu</a></div>
                <div class="2u"><a href="https://missinglight.github.io/">              <span class="image fit"><img src="assets/author_photo/yilin.jpg" alt="Yilin Cai" /></span>Yilin Cai</a></div>
                <div class="2u"><a href="https://ziyi-zhou.github.io/">                 <span class="image fit"><img src="assets/author_photo/ziyi.jpeg" alt="Ziyi Zhou" /></span>Ziyi Zhou</a></div>
                <div class="2u"><a href="https://opt2skill.github.io/">                 <span class="image fit"><img src="assets/author_photo/shijie.jpg" alt="Shijie Zhao" /></span>Shijie Zhao</a></div>
                <div class="2u"><a href="https://hyunyoungjung.github.io/">             <span class="image fit"><img src="assets/author_photo/hyunyoung.jpg" alt="Hyunyoung Jung" /></span>Hyunyoung Jung</a></div>
                <div class="2u"><a href="https://faculty.cc.gatech.edu/~sha9/">         <span class="image fit"><img src="assets/author_photo/sehoon.jpg" alt="Sehoon Ha" /></span>Sehoon Ha</a></div>
                <div class="2u"><a href="https://research.gatech.edu/people/yue-chen">  <span class="image fit"><img src="assets/author_photo/yue.jpg" alt="Yue Chen" /></span>Yue Chen</a></div>
                <div class="2u"><a href="https://faculty.cc.gatech.edu/~danfei/">       <span class="image fit"><img src="assets/author_photo/danfei.jpg" alt="Danfei Xu" /></span>Danfei Xu<sup>†</sup></a></div>
                <div class="2u"><a href="https://research.gatech.edu/people/ye-zhao">   <span class="image fit"><img src="assets/author_photo/ye.jpg" alt="Ye Zhao" /></span>Ye Zhao<sup>†</sup></a></div>
                  <!-- Add more authors in the same way -->
              </div>
          </div>

            <div class="gatech">
                <p>Georgia Institute of Technology</p>
            </div>
            <div class="button-container">
                <a href="https://opt2skill.github.io/" class="button">Paper</a>
                <a href="https://opt2skill.github.io/" class="button">Video</a>
            </div>

            <br>

            <div id="abstract" class="grid-container">
                <p>
                Humanoid robots are designed to perform diverse loco-manipulation tasks. However, they face challenges due to their high-dimensional and unstable dynamics, as well as the complex contact-rich nature of the tasks. 
                Model-based optimal control methods offer precise and systematic control but are limited by high computational complexity and accurate contact sensing. 
                On the other hand, reinforcement learning (RL) provides robustness and handles high-dimensional spaces but suffers from inefficient learning, unnatural motion, and sim-to-real gaps. 
                To address these challenges, we introduce Opt2Skill, an end-to-end pipeline that combines model-based trajectory optimization with RL to achieve robust whole- body loco-manipulation. 
                We generate reference motions for the Digit humanoid robot using differential dynamic programming (DDP) and train RL policies to track these trajectories. 
                Our results demonstrate that Opt2Skill outperforms pure RL methods in both training efficiency and task performance, with optimal trajectories that account for torque limits enhancing trajectory tracking. We successfully transfer our approach to real-world applications.
                </p>
            </div>
        </div>
    </div>
    <hr class="rounded">
    
    <div id="overview">

      

        <h1>Opt2Skill</h1>

        <p>
        Opt2Skill aims to develop loco-manipulation controllers that enable the Digit humanoid robot to track model-based optimal trajectories. 
        We start by generating whole-body reference motions that align with the robot's dynamics and meet specific motion targets using DDP through a Crocoddyl solver. These reference trajectories are then used during the training and deployment of our RL policy. 
        The RL policy augments the reference joint trajectories with a residual term, and the augmented target trajectory is fed into a low-level PD controller for the torque-controlled robot. 
        Finally, we deploy the RL policies in both simulation and real-world scenarios. 
        </p>

        <div class="approach">
            <div class="video_container">
                <video loop autoplay muted playsinline preload="metadata">
                    <source src="assets/method.mp4" type="video/mp4">
                </video>
            </div>
        </div>


        <h1>Whole-body Reference Motions Generation</h1>
        <p>
          Our approach leverages differential dynamic programming (DDP) to generate whole-body motions that obey the robot's dynamics and task requirements.
        </p>
        <div class="allegrofail">
            <div class="video_container">
                <video loop autoplay muted playsinline preload="metadata">
                    <source src="assets/TO.mp4" type="video/mp4">
                </video>
            </div>
        </div>

        <p>
          We study a rich set of loco-manipulation tasks, including walking, stair traversing, agile jumping, desk object reaching, and bulky-object handling.
          For box manipulation tasks, we design heuristic target goals for the robot's hand trajectory, accounting for the transition between contact phases with and without holding the box by adding or removing its mass and inertia from the hands.
        </p>
        <div class="allegrofail">
            <div class="video_container">
                <video loop autoplay muted playsinline preload="metadata">
                    <source src="assets/ref_motion.mp4" type="video/mp4">
                </video>
            </div>
        </div>

        <h1>Training in MuJoCo</h1>

        <p>
          We train RL-based motion imitation policies in MuJoCo simulator.
        </p>
        <div class="allegrofail">
            <div class="video_container">
                <video loop autoplay muted playsinline preload="metadata">
                    <source src="assets/training_mujoco.mp4" type="video/mp4">
                </video>
            </div>
        </div>


        <h1>Compare Pure RL with Opt2Skill</h1>

        <p>
          We compare Opt2Skill with a pure RL method that learns from scratch in three different tasks, i.e., <i>Walking</i>, <i>Box Pickup</i>, and <i>Desk Object Reaching</i>. 
          The pure RL baseline excludes reference trajectories in the observation space and the reward design.
        </p>
        <p>
          Opt2Skill shows more accurate tracking, particularly in velocity for <i>Walking</i> and end-effector positioning for <i>Box Pickup</i> and <i>Desk Object Reaching</i>. 
          In contrast, pure RL exhibits larger deviations in velocity, fails to lift the box, and could not accurately reach the target object in the <i>Desk Object Reaching</i> task.
        </p>
        <div class="allegrofail">
            <div class="video_container">
                <video loop autoplay muted playsinline preload="metadata">
                    <source src="assets/baseline.mp4" type="video/mp4">
                </video>
            </div>
        </div>


        <h1>Torque Limits and Tracking Impact</h1>

        <!--<p>
          A notable challenge in motion imitation using human pose data is that re-targeted motions may not ensure kinematic or dynamic feasibility, which can degrade tracking performance and even cause tracking failures. 
          To demonstrate how dynamics affect motion data quality, we define a <i>Jumping</i> task. We generate reference trajectories for this task with and without torque limits from the TO and analyze their difference in Opt2Skill's motion imitation performance.
          Furthermore, we analyze the effect of the torque reference on tracking accuracy.
        </p>-->
        <p>
          We demenstrate that both including the torque limit in the reference trajectory and incorporating the torque reference into reward design significantly contribute to motion tracking performance. 
          The torque limit ensures a high-quality and dynamically feasible reference trajectory, while the torque reference guides the robot to track the motion more precisely.
        </p>
        <div class="allegrofail">
            <div class="video_container">
                <video loop autoplay muted playsinline preload="metadata">
                    <source src="assets/ablation_TO.mp4" type="video/mp4">
                </video>
            </div>
        </div>


        

       
        <h1>BibTeX</h1>
         <!--<p class="bibtex">
            @article{Opt2Skill2024,<br>
            &nbsp;&nbsp;title={Opt2Skill: Imitating Dynamically-feasible Whole-Body Trajectories for Versatile Humanoid Loco-Manipulation},<br>
            &nbsp;&nbsp;author={Fukang Liu and Zhaoyuan Gu and Ziyi Zhou and Yilin Cai and Hyunyoung Jung Shijie Zhao and Sehoon Ha and Yue Chen and Danfei Xu and Ye Zhao},<br>
            &nbsp;&nbsp;year={2024},<br>
            &nbsp;&nbsp;journal={arXiv:2310.}<br>
            }
        </p>
        -->
    </div>
    <script type="text/javascript">
        /* https://stackoverflow.com/questions/3027707/how-to-change-the-playing-speed-of-videos-in-html5 */
        document.querySelector('video').defaultPlaybackRate = 1.0;
        document.querySelector('video').play();

        var videos =document.querySelectorAll('video');
        for (var i=0;i<1;i++)
        {
            videos[i].playbackRate = 1.0;
        }
    </script>
    <script>
        /* https://stackoverflow.com/questions/21163756/html5-and-javascript-to-play-videos-only-when-visible */
        var videos = document.getElementsByTagName("video");

        function checkScroll() {
            var fraction = 0.5; // Play when 70% of the player is visible.

            for(var i = 0; i < 1; i++) {  // only apply to the first video

                var video = videos[i];

                var x = video.offsetLeft, y = video.offsetTop, w = video.offsetWidth, h = video.offsetHeight, r = x + w, //right
                    b = y + h, //bottom
                    visibleX, visibleY, visible;

                visibleX = Math.max(0, Math.min(w, window.pageXOffset + window.innerWidth - x, r - window.pageXOffset));
                visibleY = Math.max(0, Math.min(h, window.pageYOffset + window.innerHeight - y, b - window.pageYOffset));

                visible = visibleX * visibleY / (w * h);

                if (visible > fraction) {
                    video.play();
                } else {
                    video.pause();
                }

            }

        }
        window.addEventListener('scroll', checkScroll, false);
        window.addEventListener('resize', checkScroll, false);
    </script>
    <script>
        document.addEventListener("DOMContentLoaded", function() {
            // Function to check if the user is on a mobile device
            function isMobileDevice() {
                return /Mobi|Android/i.test(navigator.userAgent);
            }
            // If the user is on a mobile device, disable autoplay
            if (isMobileDevice()) {
                const videos = document.querySelectorAll('video');
                videos.forEach(video => {
                    video.autoplay = false;
                    video.controls = true;
                });
            }
        });
    </script>
    <script src="https://d3e54v103j8qbb.cloudfront.net/js/jquery-3.5.1.min.dc5e7f18c8.js?site=51e0d73d83d06baa7a00000f"
            type="text/javascript" integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0="
            crossorigin="anonymous"></script>
    <script src="https://uploads-ssl.webflow.com/51e0d73d83d06baa7a00000f/js/webflow.fd002feec.js"
            type="text/javascript"></script>
  </body>

</html>
